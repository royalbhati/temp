---
layout: post
title: "DengAI: Predicting Disease Spread!"
date: 2018-09-29 14:32:20 +0300
description: Goal was to predict the total Dengue cases for each city. # Add post description (optional)
img:  # Add image post (optional)
---

Our goal is to predict the total_cases label for each (city, year, weekofyear) in the test set. There are two cities, San Juan and Iquitos, with test data for each city spanning 5 and 3 years respectively.

{% highlight python %}
  #importing required packages 
  import pandas as pd
  import numpy as np

  from matplotlib import pyplot as plt
  import seaborn as sns

  from sklearn.model_selection import train_test_split

  from warnings import filterwarnings
  filterwarnings('ignore')
{% endhighlight %}




```python
train=pd.read_csv('dengue_features_train.csv')
train_lab=pd.read_csv('dengue_labels_train.csv')
test=pd.read_csv('dengue_features_test.csv')
sample=pd.read_csv('submission_format.csv')
```


```python
#lets look at the data
```


```python
train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>city</th>
      <th>year</th>
      <th>weekofyear</th>
      <th>week_start_date</th>
      <th>ndvi_ne</th>
      <th>ndvi_nw</th>
      <th>ndvi_se</th>
      <th>ndvi_sw</th>
      <th>precipitation_amt_mm</th>
      <th>reanalysis_air_temp_k</th>
      <th>...</th>
      <th>reanalysis_precip_amt_kg_per_m2</th>
      <th>reanalysis_relative_humidity_percent</th>
      <th>reanalysis_sat_precip_amt_mm</th>
      <th>reanalysis_specific_humidity_g_per_kg</th>
      <th>reanalysis_tdtr_k</th>
      <th>station_avg_temp_c</th>
      <th>station_diur_temp_rng_c</th>
      <th>station_max_temp_c</th>
      <th>station_min_temp_c</th>
      <th>station_precip_mm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>sj</td>
      <td>1990</td>
      <td>18</td>
      <td>1990-04-30</td>
      <td>0.122600</td>
      <td>0.103725</td>
      <td>0.198483</td>
      <td>0.177617</td>
      <td>12.42</td>
      <td>297.572857</td>
      <td>...</td>
      <td>32.00</td>
      <td>73.365714</td>
      <td>12.42</td>
      <td>14.012857</td>
      <td>2.628571</td>
      <td>25.442857</td>
      <td>6.900000</td>
      <td>29.4</td>
      <td>20.0</td>
      <td>16.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>sj</td>
      <td>1990</td>
      <td>19</td>
      <td>1990-05-07</td>
      <td>0.169900</td>
      <td>0.142175</td>
      <td>0.162357</td>
      <td>0.155486</td>
      <td>22.82</td>
      <td>298.211429</td>
      <td>...</td>
      <td>17.94</td>
      <td>77.368571</td>
      <td>22.82</td>
      <td>15.372857</td>
      <td>2.371429</td>
      <td>26.714286</td>
      <td>6.371429</td>
      <td>31.7</td>
      <td>22.2</td>
      <td>8.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>sj</td>
      <td>1990</td>
      <td>20</td>
      <td>1990-05-14</td>
      <td>0.032250</td>
      <td>0.172967</td>
      <td>0.157200</td>
      <td>0.170843</td>
      <td>34.54</td>
      <td>298.781429</td>
      <td>...</td>
      <td>26.10</td>
      <td>82.052857</td>
      <td>34.54</td>
      <td>16.848571</td>
      <td>2.300000</td>
      <td>26.714286</td>
      <td>6.485714</td>
      <td>32.2</td>
      <td>22.8</td>
      <td>41.4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>sj</td>
      <td>1990</td>
      <td>21</td>
      <td>1990-05-21</td>
      <td>0.128633</td>
      <td>0.245067</td>
      <td>0.227557</td>
      <td>0.235886</td>
      <td>15.36</td>
      <td>298.987143</td>
      <td>...</td>
      <td>13.90</td>
      <td>80.337143</td>
      <td>15.36</td>
      <td>16.672857</td>
      <td>2.428571</td>
      <td>27.471429</td>
      <td>6.771429</td>
      <td>33.3</td>
      <td>23.3</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>sj</td>
      <td>1990</td>
      <td>22</td>
      <td>1990-05-28</td>
      <td>0.196200</td>
      <td>0.262200</td>
      <td>0.251200</td>
      <td>0.247340</td>
      <td>7.52</td>
      <td>299.518571</td>
      <td>...</td>
      <td>12.20</td>
      <td>80.460000</td>
      <td>7.52</td>
      <td>17.210000</td>
      <td>3.014286</td>
      <td>28.942857</td>
      <td>9.371429</td>
      <td>35.0</td>
      <td>23.9</td>
      <td>5.8</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>
</div>




```python
test.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>city</th>
      <th>year</th>
      <th>weekofyear</th>
      <th>week_start_date</th>
      <th>ndvi_ne</th>
      <th>ndvi_nw</th>
      <th>ndvi_se</th>
      <th>ndvi_sw</th>
      <th>precipitation_amt_mm</th>
      <th>reanalysis_air_temp_k</th>
      <th>...</th>
      <th>reanalysis_precip_amt_kg_per_m2</th>
      <th>reanalysis_relative_humidity_percent</th>
      <th>reanalysis_sat_precip_amt_mm</th>
      <th>reanalysis_specific_humidity_g_per_kg</th>
      <th>reanalysis_tdtr_k</th>
      <th>station_avg_temp_c</th>
      <th>station_diur_temp_rng_c</th>
      <th>station_max_temp_c</th>
      <th>station_min_temp_c</th>
      <th>station_precip_mm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>sj</td>
      <td>2008</td>
      <td>18</td>
      <td>2008-04-29</td>
      <td>-0.0189</td>
      <td>-0.018900</td>
      <td>0.102729</td>
      <td>0.091200</td>
      <td>78.60</td>
      <td>298.492857</td>
      <td>...</td>
      <td>25.37</td>
      <td>78.781429</td>
      <td>78.60</td>
      <td>15.918571</td>
      <td>3.128571</td>
      <td>26.528571</td>
      <td>7.057143</td>
      <td>33.3</td>
      <td>21.7</td>
      <td>75.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>sj</td>
      <td>2008</td>
      <td>19</td>
      <td>2008-05-06</td>
      <td>-0.0180</td>
      <td>-0.012400</td>
      <td>0.082043</td>
      <td>0.072314</td>
      <td>12.56</td>
      <td>298.475714</td>
      <td>...</td>
      <td>21.83</td>
      <td>78.230000</td>
      <td>12.56</td>
      <td>15.791429</td>
      <td>2.571429</td>
      <td>26.071429</td>
      <td>5.557143</td>
      <td>30.0</td>
      <td>22.2</td>
      <td>34.3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>sj</td>
      <td>2008</td>
      <td>20</td>
      <td>2008-05-13</td>
      <td>-0.0015</td>
      <td>NaN</td>
      <td>0.151083</td>
      <td>0.091529</td>
      <td>3.66</td>
      <td>299.455714</td>
      <td>...</td>
      <td>4.12</td>
      <td>78.270000</td>
      <td>3.66</td>
      <td>16.674286</td>
      <td>4.428571</td>
      <td>27.928571</td>
      <td>7.785714</td>
      <td>32.8</td>
      <td>22.8</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>sj</td>
      <td>2008</td>
      <td>21</td>
      <td>2008-05-20</td>
      <td>NaN</td>
      <td>-0.019867</td>
      <td>0.124329</td>
      <td>0.125686</td>
      <td>0.00</td>
      <td>299.690000</td>
      <td>...</td>
      <td>2.20</td>
      <td>73.015714</td>
      <td>0.00</td>
      <td>15.775714</td>
      <td>4.342857</td>
      <td>28.057143</td>
      <td>6.271429</td>
      <td>33.3</td>
      <td>24.4</td>
      <td>0.3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>sj</td>
      <td>2008</td>
      <td>22</td>
      <td>2008-05-27</td>
      <td>0.0568</td>
      <td>0.039833</td>
      <td>0.062267</td>
      <td>0.075914</td>
      <td>0.76</td>
      <td>299.780000</td>
      <td>...</td>
      <td>4.36</td>
      <td>74.084286</td>
      <td>0.76</td>
      <td>16.137143</td>
      <td>3.542857</td>
      <td>27.614286</td>
      <td>7.085714</td>
      <td>33.3</td>
      <td>23.3</td>
      <td>84.1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>
</div>




```python
train_lab.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>city</th>
      <th>year</th>
      <th>weekofyear</th>
      <th>total_cases</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>sj</td>
      <td>1990</td>
      <td>18</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>sj</td>
      <td>1990</td>
      <td>19</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>sj</td>
      <td>1990</td>
      <td>20</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>sj</td>
      <td>1990</td>
      <td>21</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>sj</td>
      <td>1990</td>
      <td>22</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>




```python
#descrbe

train.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>weekofyear</th>
      <th>ndvi_ne</th>
      <th>ndvi_nw</th>
      <th>ndvi_se</th>
      <th>ndvi_sw</th>
      <th>precipitation_amt_mm</th>
      <th>reanalysis_air_temp_k</th>
      <th>reanalysis_avg_temp_k</th>
      <th>reanalysis_dew_point_temp_k</th>
      <th>...</th>
      <th>reanalysis_precip_amt_kg_per_m2</th>
      <th>reanalysis_relative_humidity_percent</th>
      <th>reanalysis_sat_precip_amt_mm</th>
      <th>reanalysis_specific_humidity_g_per_kg</th>
      <th>reanalysis_tdtr_k</th>
      <th>station_avg_temp_c</th>
      <th>station_diur_temp_rng_c</th>
      <th>station_max_temp_c</th>
      <th>station_min_temp_c</th>
      <th>station_precip_mm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1456.000000</td>
      <td>1456.000000</td>
      <td>1262.000000</td>
      <td>1404.000000</td>
      <td>1434.000000</td>
      <td>1434.000000</td>
      <td>1443.000000</td>
      <td>1446.000000</td>
      <td>1446.000000</td>
      <td>1446.000000</td>
      <td>...</td>
      <td>1446.000000</td>
      <td>1446.000000</td>
      <td>1443.000000</td>
      <td>1446.000000</td>
      <td>1446.000000</td>
      <td>1413.000000</td>
      <td>1413.000000</td>
      <td>1436.000000</td>
      <td>1442.000000</td>
      <td>1434.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2001.031593</td>
      <td>26.503434</td>
      <td>0.142294</td>
      <td>0.130553</td>
      <td>0.203783</td>
      <td>0.202305</td>
      <td>45.760388</td>
      <td>298.701852</td>
      <td>299.225578</td>
      <td>295.246356</td>
      <td>...</td>
      <td>40.151819</td>
      <td>82.161959</td>
      <td>45.760388</td>
      <td>16.746427</td>
      <td>4.903754</td>
      <td>27.185783</td>
      <td>8.059328</td>
      <td>32.452437</td>
      <td>22.102150</td>
      <td>39.326360</td>
    </tr>
    <tr>
      <th>std</th>
      <td>5.408314</td>
      <td>15.019437</td>
      <td>0.140531</td>
      <td>0.119999</td>
      <td>0.073860</td>
      <td>0.083903</td>
      <td>43.715537</td>
      <td>1.362420</td>
      <td>1.261715</td>
      <td>1.527810</td>
      <td>...</td>
      <td>43.434399</td>
      <td>7.153897</td>
      <td>43.715537</td>
      <td>1.542494</td>
      <td>3.546445</td>
      <td>1.292347</td>
      <td>2.128568</td>
      <td>1.959318</td>
      <td>1.574066</td>
      <td>47.455314</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1990.000000</td>
      <td>1.000000</td>
      <td>-0.406250</td>
      <td>-0.456100</td>
      <td>-0.015533</td>
      <td>-0.063457</td>
      <td>0.000000</td>
      <td>294.635714</td>
      <td>294.892857</td>
      <td>289.642857</td>
      <td>...</td>
      <td>0.000000</td>
      <td>57.787143</td>
      <td>0.000000</td>
      <td>11.715714</td>
      <td>1.357143</td>
      <td>21.400000</td>
      <td>4.528571</td>
      <td>26.700000</td>
      <td>14.700000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1997.000000</td>
      <td>13.750000</td>
      <td>0.044950</td>
      <td>0.049217</td>
      <td>0.155087</td>
      <td>0.144209</td>
      <td>9.800000</td>
      <td>297.658929</td>
      <td>298.257143</td>
      <td>294.118929</td>
      <td>...</td>
      <td>13.055000</td>
      <td>77.177143</td>
      <td>9.800000</td>
      <td>15.557143</td>
      <td>2.328571</td>
      <td>26.300000</td>
      <td>6.514286</td>
      <td>31.100000</td>
      <td>21.100000</td>
      <td>8.700000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2002.000000</td>
      <td>26.500000</td>
      <td>0.128817</td>
      <td>0.121429</td>
      <td>0.196050</td>
      <td>0.189450</td>
      <td>38.340000</td>
      <td>298.646429</td>
      <td>299.289286</td>
      <td>295.640714</td>
      <td>...</td>
      <td>27.245000</td>
      <td>80.301429</td>
      <td>38.340000</td>
      <td>17.087143</td>
      <td>2.857143</td>
      <td>27.414286</td>
      <td>7.300000</td>
      <td>32.800000</td>
      <td>22.200000</td>
      <td>23.850000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2005.000000</td>
      <td>39.250000</td>
      <td>0.248483</td>
      <td>0.216600</td>
      <td>0.248846</td>
      <td>0.246982</td>
      <td>70.235000</td>
      <td>299.833571</td>
      <td>300.207143</td>
      <td>296.460000</td>
      <td>...</td>
      <td>52.200000</td>
      <td>86.357857</td>
      <td>70.235000</td>
      <td>17.978214</td>
      <td>7.625000</td>
      <td>28.157143</td>
      <td>9.566667</td>
      <td>33.900000</td>
      <td>23.300000</td>
      <td>53.900000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2010.000000</td>
      <td>53.000000</td>
      <td>0.508357</td>
      <td>0.454429</td>
      <td>0.538314</td>
      <td>0.546017</td>
      <td>390.600000</td>
      <td>302.200000</td>
      <td>302.928571</td>
      <td>298.450000</td>
      <td>...</td>
      <td>570.500000</td>
      <td>98.610000</td>
      <td>390.600000</td>
      <td>20.461429</td>
      <td>16.028571</td>
      <td>30.800000</td>
      <td>15.800000</td>
      <td>42.200000</td>
      <td>25.600000</td>
      <td>543.300000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 22 columns</p>
</div>




```python
#lets see how much data is missing
```


```python
#missing train data

missing_df = train.isnull().sum(axis=0).reset_index()
missing_df.columns = ['column_name', 'missing_count']
missing_df = missing_df[missing_df['missing_count']>0]
missing_df = missing_df.sort_values(by='missing_count')
missing_df['precent']=missing_df['missing_count']/train.shape[0]*100
missing_df

```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>column_name</th>
      <th>missing_count</th>
      <th>precent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13</th>
      <td>reanalysis_min_air_temp_k</td>
      <td>10</td>
      <td>0.686813</td>
    </tr>
    <tr>
      <th>18</th>
      <td>reanalysis_tdtr_k</td>
      <td>10</td>
      <td>0.686813</td>
    </tr>
    <tr>
      <th>17</th>
      <td>reanalysis_specific_humidity_g_per_kg</td>
      <td>10</td>
      <td>0.686813</td>
    </tr>
    <tr>
      <th>9</th>
      <td>reanalysis_air_temp_k</td>
      <td>10</td>
      <td>0.686813</td>
    </tr>
    <tr>
      <th>10</th>
      <td>reanalysis_avg_temp_k</td>
      <td>10</td>
      <td>0.686813</td>
    </tr>
    <tr>
      <th>11</th>
      <td>reanalysis_dew_point_temp_k</td>
      <td>10</td>
      <td>0.686813</td>
    </tr>
    <tr>
      <th>12</th>
      <td>reanalysis_max_air_temp_k</td>
      <td>10</td>
      <td>0.686813</td>
    </tr>
    <tr>
      <th>14</th>
      <td>reanalysis_precip_amt_kg_per_m2</td>
      <td>10</td>
      <td>0.686813</td>
    </tr>
    <tr>
      <th>15</th>
      <td>reanalysis_relative_humidity_percent</td>
      <td>10</td>
      <td>0.686813</td>
    </tr>
    <tr>
      <th>8</th>
      <td>precipitation_amt_mm</td>
      <td>13</td>
      <td>0.892857</td>
    </tr>
    <tr>
      <th>16</th>
      <td>reanalysis_sat_precip_amt_mm</td>
      <td>13</td>
      <td>0.892857</td>
    </tr>
    <tr>
      <th>22</th>
      <td>station_min_temp_c</td>
      <td>14</td>
      <td>0.961538</td>
    </tr>
    <tr>
      <th>21</th>
      <td>station_max_temp_c</td>
      <td>20</td>
      <td>1.373626</td>
    </tr>
    <tr>
      <th>23</th>
      <td>station_precip_mm</td>
      <td>22</td>
      <td>1.510989</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ndvi_se</td>
      <td>22</td>
      <td>1.510989</td>
    </tr>
    <tr>
      <th>7</th>
      <td>ndvi_sw</td>
      <td>22</td>
      <td>1.510989</td>
    </tr>
    <tr>
      <th>19</th>
      <td>station_avg_temp_c</td>
      <td>43</td>
      <td>2.953297</td>
    </tr>
    <tr>
      <th>20</th>
      <td>station_diur_temp_rng_c</td>
      <td>43</td>
      <td>2.953297</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ndvi_nw</td>
      <td>52</td>
      <td>3.571429</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ndvi_ne</td>
      <td>194</td>
      <td>13.324176</td>
    </tr>
  </tbody>
</table>
</div>




```python
# missing test data

missing_df = test.isnull().sum(axis=0).reset_index()
missing_df.columns = ['column_name', 'missing_count']
missing_df = missing_df[missing_df['missing_count']>0]
missing_df = missing_df.sort_values(by='missing_count')
missing_df['precent']=missing_df['missing_count']/test.shape[0]*100
missing_df

```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>column_name</th>
      <th>missing_count</th>
      <th>precent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>ndvi_se</td>
      <td>1</td>
      <td>0.240385</td>
    </tr>
    <tr>
      <th>7</th>
      <td>ndvi_sw</td>
      <td>1</td>
      <td>0.240385</td>
    </tr>
    <tr>
      <th>13</th>
      <td>reanalysis_min_air_temp_k</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>8</th>
      <td>precipitation_amt_mm</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>9</th>
      <td>reanalysis_air_temp_k</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>10</th>
      <td>reanalysis_avg_temp_k</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>11</th>
      <td>reanalysis_dew_point_temp_k</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>12</th>
      <td>reanalysis_max_air_temp_k</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>18</th>
      <td>reanalysis_tdtr_k</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>14</th>
      <td>reanalysis_precip_amt_kg_per_m2</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>15</th>
      <td>reanalysis_relative_humidity_percent</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>16</th>
      <td>reanalysis_sat_precip_amt_mm</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>17</th>
      <td>reanalysis_specific_humidity_g_per_kg</td>
      <td>2</td>
      <td>0.480769</td>
    </tr>
    <tr>
      <th>21</th>
      <td>station_max_temp_c</td>
      <td>3</td>
      <td>0.721154</td>
    </tr>
    <tr>
      <th>23</th>
      <td>station_precip_mm</td>
      <td>5</td>
      <td>1.201923</td>
    </tr>
    <tr>
      <th>22</th>
      <td>station_min_temp_c</td>
      <td>9</td>
      <td>2.163462</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ndvi_nw</td>
      <td>11</td>
      <td>2.644231</td>
    </tr>
    <tr>
      <th>19</th>
      <td>station_avg_temp_c</td>
      <td>12</td>
      <td>2.884615</td>
    </tr>
    <tr>
      <th>20</th>
      <td>station_diur_temp_rng_c</td>
      <td>12</td>
      <td>2.884615</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ndvi_ne</td>
      <td>43</td>
      <td>10.336538</td>
    </tr>
  </tbody>
</table>
</div>




```python
#not much of the data is missing but since we have less data overall we 
#need to fill it smartly to get most out of the model

```


```python
#for the time being lets fill them with mean

def fill_missing(df,test):
    for i,j in enumerate(df.isnull().any()):
        if j==True:
            if df[df.columns[i]].dtypes=='object':
                df[df.columns[i]].fillna(value=df[df.columns[i]].mode()[0], inplace=True)
                test[test.columns[i]].fillna(value=test[test.columns[i]].mode()[0], inplace=True)
            else:
                df[df.columns[i]].fillna(value=df[df.columns[i]].mean(), inplace=True)
                test[test.columns[i]].fillna(value=test[test.columns[i]].mean(), inplace=True)
```


```python
fill_missing(train,test)
```


```python
#lets explore the columns
```


```python
train['ndvi_sw'].plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fd277af6438>




![png](output_14_1.png)



```python
train['ndvi_se'].plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fd277b93160>




![png](output_15_1.png)



```python
train['ndvi_nw'].plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fd277bab320>




![png](output_16_1.png)



```python
train['ndvi_ne'].plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fd277be3400>




![png](output_17_1.png)



```python
# From above plots it can be seen that there are two distribution
# one for SJ and aother for IQ
```


```python


```


```python
# lets look at the traget variable
```


```python
sns.distplot(train_lab['total_cases'],bins=10,kde=False)
```

    /home/royal/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.
      warnings.warn("The 'normed' kwarg is deprecated, and has been "





    <matplotlib.axes._subplots.AxesSubplot at 0x7fd26e3774a8>




![png](output_21_2.png)

Our target variable, total_cases is a non-negative integer, which means we're looking to make some count predictions. Standard regression techniques for this type of prediction include

* Poisson regression
* Negative binomial regression



- Poisson regression fits according to the assumption that the mean and variance of the population distributiona are equal. 

-When they aren't, specifically when the variance is much larger than the mean, the negative binomial approach is better. Why? It isn't magic. The negative binomial regression simply lifts the assumption that the population mean and variance are equal, allowing for a larger class of possible models. 

In fact, from this perspective, the Poisson distribution is but a special case of the negative binomial distribution.

```python
#lets look at our data
```


```python
'mean:',train_lab['total_cases'].mean(),'var:',train_lab['total_cases'].var()

```




    ('mean:', 24.67513736263736, 'var:', 1900.6112302216602)




```python
# we need to use the negative binomial approach
```

Lets look at the correlation of the variables


```python
train['target']=train_lab['total_cases']
```


```python
corre = train.corr()



mask = np.zeros_like(corre, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(220, 10, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corre,cmap=cmap)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fd26d71b0b8>




![png](output_28_1.png)



```python
f, ax = plt.subplots(figsize=(11, 9))


corre['target'].sort_values(ascending=False).plot(kind='barh',ax=ax)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fd26b562ef0>




![png](output_29_1.png)


A few observations

The correlation strengths differ for each city, but it looks like reanalysis_specific_humidity_g_per_kg 
and reanalysis_dew_point_temp_k are the most strongly correlated with total_cases. 
This makes sense: we know mosquitos thrive wet climates, the wetter the better!


```python
from sklearn.model_selection import train_test_split

dev_X, val_X, dev_y, val_y = train_test_split(train, train.target, test_size = 0.2, random_state = 42)

```


```python
train.columns
```




    Index(['city', 'year', 'weekofyear', 'week_start_date', 'ndvi_ne', 'ndvi_nw',
           'ndvi_se', 'ndvi_sw', 'precipitation_amt_mm', 'reanalysis_air_temp_k',
           'reanalysis_avg_temp_k', 'reanalysis_dew_point_temp_k',
           'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k',
           'reanalysis_precip_amt_kg_per_m2',
           'reanalysis_relative_humidity_percent', 'reanalysis_sat_precip_amt_mm',
           'reanalysis_specific_humidity_g_per_kg', 'reanalysis_tdtr_k',
           'station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c',
           'station_min_temp_c', 'station_precip_mm', 'target'],
          dtype='object')




```python
import statsmodels.api as sm

from statsmodels.tools import eval_measures
import statsmodels.formula.api as smf

def get_best_model(train, test):
    # Step 1: specify the form of the model
    model_formula = "target ~ reanalysis_specific_humidity_g_per_kg + reanalysis_dew_point_temp_k +station_min_temp_c+station_avg_temp_c"
    model = smf.glm(formula=model_formula,
                    data=train,
                    family=sm.families.NegativeBinomial(alpha=1e-08))

    fitted_model = model.fit()
    pred=fitted_model.predict(test)
    
    return pred
```


```python
bestmodel = get_best_model(train, test)
```


```python
sample['total_cases']=bestmodel
```


```python
sample['total_cases']=sample['total_cases'].round()
```


```python
sample['total_cases']=sample['total_cases'].astype(np.int64)
```


```python
sample.to_csv('aaa.csv',index=False)
```

